import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from "https://esm.sh/@supabase/supabase-js@2";

/**
 * Admin endpoint to score LLM interactions for hallucination
 * 
 * POST /functions/v1/score-llm-batch
 * 
 * Headers:
 *   Authorization: Bearer <ADMIN_TOKEN> (optional)
 * 
 * This is an INTERNAL ADMIN endpoint. Call manually or via cron.
 * 
 * Environment variables:
 *   SUPABASE_URL - Supabase project URL
 *   SUPABASE_SERVICE_ROLE_KEY - Service role key
 *   OPENAI_API_KEY - OpenAI API key (optional - if not set, interactions are skipped)
 *   MONAI_ADMIN_TOKEN - Optional admin token
 *   LOVABLE_API_KEY - Lovable AI key (fallback if no OpenAI key)
 */

const corsHeaders = {
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Headers": "authorization, x-client-info, apikey, content-type",
};

// Send Slack notification
async function sendSlackAlert(webhookUrl: string, message: string): Promise<void> {
  try {
    await fetch(webhookUrl, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ text: message }),
    });
  } catch (error) {
    console.error("Failed to send Slack alert:", error);
  }
}

// Score using Lovable AI or OpenAI
async function scoreWithAI(userQuery: string, modelOutput: string): Promise<{ score: number; explanation: string }> {
  const openaiKey = Deno.env.get("OPENAI_API_KEY");
  const lovableKey = Deno.env.get("LOVABLE_API_KEY");

  const prompt = `You are an AI response quality analyzer. Analyze the following LLM interaction for potential hallucination.

User Query: "${userQuery}"

Model Output: "${modelOutput}"

Score the response for hallucination risk on a scale from 0 to 1:
- 0.0-0.2: Highly factual, well-grounded response
- 0.2-0.4: Mostly accurate with minor uncertainties
- 0.4-0.6: Some potentially unverifiable claims
- 0.6-0.8: Multiple unsupported or likely false claims
- 0.8-1.0: Significant fabrication or hallucination

Respond with ONLY valid JSON in this exact format:
{"score": 0.XX, "explanation": "Brief explanation of the score"}`;

  if (lovableKey) {
    // Use Lovable AI Gateway
    const response = await fetch("https://ai.gateway.lovable.dev/v1/chat/completions", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${lovableKey}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "google/gemini-2.5-flash",
        messages: [
          { role: "system", content: "You are a hallucination detection system. Always respond with valid JSON only." },
          { role: "user", content: prompt }
        ],
        temperature: 0.3,
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error("Lovable AI error:", errorText);
      throw new Error(`Lovable AI request failed: ${response.status}`);
    }

    const data = await response.json();
    const content = data.choices?.[0]?.message?.content || "";
    
    try {
      // Extract JSON from response
      const jsonMatch = content.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        const parsed = JSON.parse(jsonMatch[0]);
        return {
          score: Math.max(0, Math.min(1, Number(parsed.score) || 0.5)),
          explanation: parsed.explanation || "Score generated by AI analysis",
        };
      }
    } catch (e) {
      console.error("Failed to parse AI response:", content);
    }
    
    return { score: 0.5, explanation: "Could not parse AI response" };

  } else if (openaiKey) {
    // Use OpenAI directly
    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${openaiKey}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "gpt-4o-mini",
        messages: [
          { role: "system", content: "You are a hallucination detection system. Always respond with valid JSON only." },
          { role: "user", content: prompt }
        ],
        temperature: 0.3,
      }),
    });

    if (!response.ok) {
      throw new Error(`OpenAI request failed: ${response.status}`);
    }

    const data = await response.json();
    const content = data.choices?.[0]?.message?.content || "";
    
    try {
      const jsonMatch = content.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        const parsed = JSON.parse(jsonMatch[0]);
        return {
          score: Math.max(0, Math.min(1, Number(parsed.score) || 0.5)),
          explanation: parsed.explanation || "Score generated by AI analysis",
        };
      }
    } catch (e) {
      console.error("Failed to parse OpenAI response:", content);
    }
    
    return { score: 0.5, explanation: "Could not parse AI response" };
  }

  throw new Error("No AI API key configured");
}

serve(async (req) => {
  if (req.method === "OPTIONS") {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const supabaseUrl = Deno.env.get("SUPABASE_URL")!;
    const supabaseServiceKey = Deno.env.get("SUPABASE_SERVICE_ROLE_KEY")!;
    const adminToken = Deno.env.get("MONAI_ADMIN_TOKEN");
    const hasAIKey = Deno.env.get("OPENAI_API_KEY") || Deno.env.get("LOVABLE_API_KEY");

    // Optional admin auth
    if (adminToken) {
      const authHeader = req.headers.get("authorization");
      if (!authHeader || authHeader !== `Bearer ${adminToken}`) {
        return new Response(
          JSON.stringify({ error: "Unauthorized" }),
          { status: 401, headers: { ...corsHeaders, "Content-Type": "application/json" } }
        );
      }
    }

    const supabase = createClient(supabaseUrl, supabaseServiceKey);

    // Fetch pending interactions
    const { data: pendingEvents, error: fetchError } = await supabase
      .from("monai_llm_interactions")
      .select("id, project_id, input_text, output_text")
      .eq("status", "pending_score")
      .order("created_at", { ascending: true })
      .limit(10);

    if (fetchError) {
      console.error("Failed to fetch pending events:", fetchError);
      return new Response(
        JSON.stringify({ error: "Failed to fetch pending events" }),
        { status: 500, headers: { ...corsHeaders, "Content-Type": "application/json" } }
      );
    }

    if (!pendingEvents || pendingEvents.length === 0) {
      return new Response(
        JSON.stringify({ status: "ok", message: "No pending events to score", processed: 0 }),
        { status: 200, headers: { ...corsHeaders, "Content-Type": "application/json" } }
      );
    }

    // If no AI key, skip all
    if (!hasAIKey) {
      const ids = pendingEvents.map(e => e.id);
      await supabase
        .from("monai_llm_interactions")
        .update({ status: "skipped" })
        .in("id", ids);

      return new Response(
        JSON.stringify({ 
          status: "ok", 
          message: "No AI API key configured. Events marked as skipped.", 
          processed: pendingEvents.length,
          skipped: true 
        }),
        { status: 200, headers: { ...corsHeaders, "Content-Type": "application/json" } }
      );
    }

    const results: any[] = [];
    const projectScores: Map<string, number[]> = new Map();

    for (const event of pendingEvents) {
      try {
        const { score, explanation } = await scoreWithAI(event.input_text, event.output_text);

        // Insert score
        await supabase
          .from("llm_scores")
          .insert({
            project_id: event.project_id,
            llm_event_id: event.id,
            hallucination_score: score,
            explanation: explanation,
          });

        // Update interaction status and score
        await supabase
          .from("monai_llm_interactions")
          .update({ 
            status: "scored",
            hallucination_score: score,
          })
          .eq("id", event.id);

        // Track for summary
        if (!projectScores.has(event.project_id)) {
          projectScores.set(event.project_id, []);
        }
        projectScores.get(event.project_id)!.push(score);

        results.push({
          event_id: event.id,
          score,
          explanation,
          status: "scored",
        });

        console.log(`Scored event ${event.id}: ${score.toFixed(3)}`);

      } catch (error) {
        console.error(`Failed to score event ${event.id}:`, error);
        
        await supabase
          .from("monai_llm_interactions")
          .update({ status: "skipped" })
          .eq("id", event.id);

        results.push({
          event_id: event.id,
          status: "skipped",
          error: error instanceof Error ? error.message : "Unknown error",
        });
      }
    }

    // Update daily summaries and check for alerts
    for (const [projectId, scores] of projectScores) {
      const today = new Date().toISOString().split("T")[0];

      // Get project info
      const { data: project } = await supabase
        .from("monai_projects")
        .select("name, hallucination_threshold, slack_webhook_url")
        .eq("id", projectId)
        .single();

      const threshold = project?.hallucination_threshold || 0.3;

      // Get existing summary for today
      const { data: existingSummary } = await supabase
        .from("llm_summary_daily")
        .select("*")
        .eq("project_id", projectId)
        .eq("date", today)
        .maybeSingle();

      // Get all scores for today
      const { data: todayScores } = await supabase
        .from("llm_scores")
        .select("hallucination_score")
        .eq("project_id", projectId)
        .gte("created_at", `${today}T00:00:00`)
        .lte("created_at", `${today}T23:59:59`);

      if (todayScores && todayScores.length > 0) {
        const allScores = todayScores.map(s => s.hallucination_score);
        const avg = allScores.reduce((a, b) => a + b, 0) / allScores.length;
        const highCount = allScores.filter(s => s >= threshold).length;
        const highFraction = highCount / allScores.length;

        // Upsert summary
        await supabase
          .from("llm_summary_daily")
          .upsert({
            project_id: projectId,
            date: today,
            avg_hallucination_score: avg,
            high_hallucination_fraction: highFraction,
            total_events: allScores.length,
            high_events: highCount,
          }, { onConflict: "project_id,date" });

        // Check for alert
        if (highFraction >= threshold) {
          await supabase
            .from("monai_alerts")
            .insert({
              project_id: projectId,
              type: "hallucination",
              severity: highFraction >= 0.5 ? "critical" : "warning",
              title: "High hallucination rate detected",
              message: `${(highFraction * 100).toFixed(1)}% of interactions (${highCount}/${allScores.length}) exceeded threshold`,
              payload_json: {
                date: today,
                avg_score: avg,
                high_fraction: highFraction,
                total_events: allScores.length,
                high_events: highCount,
              },
            });

          // Send Slack notification
          if (project?.slack_webhook_url) {
            await sendSlackAlert(
              project.slack_webhook_url,
              `⚠️ MonAI hallucination alert for ${project.name}: ${(highFraction * 100).toFixed(1)}% high hallucination rate (${highCount}/${allScores.length} interactions)`
            );
          }

          // Log event
          await supabase
            .from("monai_events")
            .insert({
              project_id: projectId,
              event_type: "alert_created",
              payload_json: { type: "hallucination", high_fraction: highFraction },
            });
        }
      }
    }

    return new Response(
      JSON.stringify({ status: "ok", processed: results.length, results }),
      { status: 200, headers: { ...corsHeaders, "Content-Type": "application/json" } }
    );

  } catch (error) {
    console.error("Error in score-llm-batch:", error);
    return new Response(
      JSON.stringify({ error: error instanceof Error ? error.message : "Internal server error" }),
      { status: 500, headers: { ...corsHeaders, "Content-Type": "application/json" } }
    );
  }
});
